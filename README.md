# SE_annotation
Super enhancers (SE) are long regulatory sequences in the genome that play an important role in enhancing the expression of certain genes. They largely determine the morphology and function of cells. It has been shown that changes in their structure and activity in many cases lead to cancerous transformation and the development of other diseases (Whyte et al., 2013; Parker et al., 2013). Most of the existing algorithms for their search require not only the DNA sequence, but also the data of expensive additional experiments. The aim of this work is to develop a SE search tool using only DNA sequence information. <br>
<br>
To solve the problem of searching for super enhancers, classical methods, machine learning approaches, including neural networks, were used. Most algorithms use data from Chip-Seq experiments, which provide information about SE key marks and are extremely useful for searches, but some researchers are taking steps to move away from using Chip-Seq data. Existing algorithms are aimed at classifying enhancers into conventional (TE) and super enhancers (SE).<br>
<br>
At the moment, the most used tool and the gold standard for solving this problem is the linear ROSE algorithm (Whyte et al., 2013; Lovén et al., 2013). An ML analysis of the importance of SE features was performed and the imPROSE (Integrated Super Enhancer Prediction Methods) tool was developed based on ML algorithms to predict which enhancers are SE (Khan, A., Zhang, X, 2019). ChIP-seq data, RNA-seq data, gene ontology, and DNA motifs were analyzed. They implemented six classic machine learning models including Random Forest, linear SVM, k-NN, AdaBoost, Naive Bayes, and Decision Tree, performed 10-fold cross-validation and compared them. The best results were shown by Random Forest (AUC=0.98). When only characterizing DNA sequences, such as phastCons, GC content, and repeat fractions, the authors estimated AUC = 0.81. This shows that only the characteristics of the DNA group protocol distinguish between TE and SE. With a possible neural network approach came the idea of using them to predict SE. There are works offering Convolutional Neural Networks (CNNs) solving this furniture. DEEPSEN, CNN implemented in 2019 was the first NN model implemented for this purpose (Bu et al., 2019). The next step was the implementation of DeepSE in 2021 (Ji et al., 2021). It outperformed the methods available at the time, using only sequence feature embeddings. A new moment was the use of k-mer sequence embeddings obtained by training dna2vec on genomes. Then the CNN classifier with 2 convolutional and 2 fully connected layers performs a binary classification (TE or SE). This tool has not gained popularity. At relatively high accuracy values, the precision metric did not exceed 0.48, while f1 did not exceed 0.52. In my work, it is planned to obtain results comparable to the results of models based on Chip-Seq data.<br>
<br>
For similar tasks, CNN, RNN, hybrid models (Gunasekaran et al., 2021), transformers were used. For enhancer annotation (TE), a task similar to that of this study, a hybrid model based on CNN and RNN was used: a convolutional neural network (CNN) followed by a recurrent neural network (RNN). They have been used to predict enhancer regions with histone modification marks as input (Lim et al., 2019). For the same TE prediction task, a BERT-based CNN architecture was created using only the DNA sequence as input (Le et al., 2021).<br>
<br>
For the annotation of various non-protein-coding genetic elements, which, however, have an important regulatory role, the DNABERT architecture was created, a pre-trained model is available. It can potentially be used for a variety of DNA sequence analysis tasks, including annotation of enhancers and super enhancers (Ji et al., 2021). In this project we plan to try using BERT and maybe apply transfer learning.
## Background
### DNABERT
In this project were are planning to use DNABERT architecture (Ji et al., 2021) and perform fine-tuning to solve the task of classification of sequences into two classes (SEs and TEs). The code of DNABERT can be found here https://github.com/jerryji1993/DNABERT <br>
<br>
The authors tokenized a DNA sequence with the k-mer representation. For example, a DNA sequence ‘ATGGCT’ can be tokenized to a sequence of four 3-mers: {ATG, TGG, GGC, GCT} or to a sequence of two 5-mers: {ATGGC, TGGCT}. Since different k leads to different tokenization of a DNA sequence. The authors advise to use 6-mers and DNABERT-6 model. <br>
<br>
DNABERT takes a sequence with a max length of 512 as input. For sequences longer than 512, Ji and colleagues splited them into pieces and concatenate their representations as the final representation. <br>
<br>
The example train data represents splited into k-mers DNA sequence and class labels. 
### Data
We are planning to use data obtained from 9 different cell types by Ji et al. https://github.com/QiaoyingJi/DeepSE. The data is presented in csv format and should be convered into the format that can be used for DNABERT fine-tuning. For this purpose we use a converter which can be found in ./data. <br>
## Literature
1) Whyte WA, Orlando DA, Hnisz D, Abraham BJ, Lin CY, Kagey MH, Rahl PB, Lee TI, Young RA. Master transcription factors and mediator establish super-enhancers at key cell identity genes. Cell. 2013 Apr 11;153(2):307-19. doi: 10.1016/j.cell.2013.03.035. PMID: 23582322; PMCID: PMC3653129. <br>
2) Parker SC, Stitzel ML, Taylor DL, Orozco JM, Erdos MR, Akiyama JA, van Bueren KL, Chines PS, Narisu N; NISC Comparative Sequencing Program; Black BL, Visel A, Pennacchio LA, Collins FS; National Institutes of Health Intramural Sequencing Center Comparative Sequencing Program Authors; NISC Comparative Sequencing Program Authors. Chromatin stretch enhancer states drive cell-specific gene regulation and harbor human disease risk variants. Proc Natl Acad Sci U S A. 2013 Oct 29;110(44):17921-6. doi: 10.1073/pnas.1317023110. Epub 2013 Oct 14. PMID: 24127591; PMCID: PMC3816444. <br>
3) Lovén J, Hoke HA, Lin CY, Lau A, Orlando DA, Vakoc CR, Bradner JE, Lee TI, Young RA. Selective inhibition of tumor oncogenes by disruption of super-enhancers. Cell. 2013 Apr 11;153(2):320-34. doi: 10.1016/j.cell.2013.03.036. PMID: 23582323; PMCID: PMC3760967.
4) Khan, A., Zhang, X. Integrative modeling reveals key chromatin and sequence signatures predicting super-enhancers. Sci Rep 9, 2877 (2019). https://doi.org/10.1038/s41598-019-38979-9
5) Bu H, Hao J, Gan Y, Zhou S, Guan J. DEEPSEN: a convolutional neural network based method for super-enhancer prediction. BMC Bioinformatics. 2019 Dec 24;20(Suppl 15):598. doi: 10.1186/s12859-019-3180-z. PMID: 31874597; PMCID: PMC6929276.
6) Ji QY, Gong XJ, Li HM, Du PF. DeepSE: Detecting super-enhancers among typical enhancers using only sequence feature embeddings. Genomics. 2021 Nov;113(6):4052-4060. doi: 10.1016/j.ygeno.2021.10.007. Epub 2021 Oct 16. PMID: 34666191.
7) Gunasekaran H, Ramalakshmi K, Rex Macedo Arokiaraj A, Deepa Kanmani S, Venkatesan C, Suresh Gnana Dhas C. Analysis of DNA Sequence Classification Using CNN and Hybrid Models. Comput Math Methods Med. 2021 Jul 15;2021:1835056. doi: 10.1155/2021/1835056. PMID: 34306171; PMCID: PMC8285202.
8)Lim A, Lim S, Kim S. Enhancer prediction with histone modification marks using a hybrid neural network model. Methods. 2019 Aug 15;166:48-56. doi: 10.1016/j.ymeth.2019.03.014. Epub 2019 Mar 21. PMID: 30905748.
9) Le NQK, Ho QT, Nguyen TT, Ou YY. A transformer architecture based on BERT and 2D convolutional neural network to identify DNA enhancers from sequence information. Brief Bioinform. 2021 Sep 2;22(5):bbab005. doi: 10.1093/bib/bbab005. PMID: 33539511.
10) Ji Y, Zhou Z, Liu H, Davuluri RV. DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome. Bioinformatics. 2021 Feb 4:btab083. doi: 10.1093/bioinformatics/btab083. Epub ahead of print. PMID: 33538820.
